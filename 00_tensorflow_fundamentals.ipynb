{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46664329",
   "metadata": {},
   "source": [
    "# 00. Getting Started with TensorFlow: A guide to the fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5ed8d",
   "metadata": {},
   "source": [
    "## What is tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8066f27",
   "metadata": {},
   "source": [
    "[TensorFlow](https://www.tensorflow.org/) is an open-source end-to-end machine learning library for preprocessing data, modelling data and serving models (getting them into the hands of others)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c61589",
   "metadata": {},
   "source": [
    "## Why Use Tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832121b",
   "metadata": {},
   "source": [
    "Rather than building Machine Learning and Deep Learning models from scratch, it's more likely you'll use a library such as Tensorflow. This is because it contains many of the most common Machine Learning functions you'll want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe338664",
   "metadata": {},
   "source": [
    "## What we're going to Cover?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290f323",
   "metadata": {},
   "source": [
    "Tensorflow is vast. But the main premise is simple: turns data into numbers (tensors) and build machine learning algorithms to find patterns in them. \n",
    "\n",
    "In this notebook we cover some of the most fundamentals Tensorflow operations more specificially:\n",
    "\n",
    "* Introduction to tensors (creating tensors)\n",
    "* Getting information from tensors (tensor attributes)\n",
    "* Manipulating tensors (tensor operations)\n",
    "* Tensors and NumPy\n",
    "* Using `@tf.function` (a way to speed up your regular Python functions)\n",
    "* Using GPUs with TensorFlow\n",
    "* Exercises to try\n",
    "\n",
    "Things to note:\n",
    "\n",
    "* Many of the conventions here will happen automatically behind the scenes (when you build a model) but it's worth knowing so if you see any of these things, you know what's happening. \n",
    "* For any TensorFlow function you see, it's important to be able to check it out in the documentation, for example, going to the Python API docs for all functions and searching for what you need: https://www.tensorflow.org/api_docs/python/ (don't worry if this seems overwhelming at first, with enough practice, you'll get used to navigating the documentaiton)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e26d54",
   "metadata": {},
   "source": [
    "## Introduction to Tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3ab21",
   "metadata": {},
   "source": [
    "If you've every used NumPy, [tensors](https://www.tensorflow.org/guide/tensor) are the kind of like NumPy arrays (we'll see more on this later). \n",
    "\n",
    "For the shake this notebook and going forward, you can think of a tensor as a multi-dimensional numerical representation (also referred to as n-dimensional, where n can be any number) of something. Where something can be almost anything you can imagine:\n",
    "\n",
    "* It could be numbers themselves <br>For example: Using tensors to represent the price of cars.\n",
    "* It could be an image <br> For example: Using tensors to represent the pixels of image. \n",
    "* It could be text  <br> For example: Using tensors to represent word\n",
    "* It could be some other form of information or data you want to represent with numbers. \n",
    "\n",
    "#### Question may arises in our, so what will be the main difference between tensors and NumPy.\n",
    "\n",
    "The main difference between tensors and Numpy (also known as n-dimensional arrays of number) is that tensors can be used on [GPUs (graphical processing units)](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/) and [TPUs (tensor processing units)](https://en.wikipedia.org/wiki/Tensor_processing_unit). \n",
    "\n",
    "The benefit of being able to run on GPUs and TPUs is faster computation, this means, if we wanted to find patterns in the numerical representations of our data, we can generally find them faster using GPUs and TPUs.\n",
    "\n",
    "Okay, we've been talking enough about tensors, let's see them.\n",
    "\n",
    "The first thing we'll do is import TensorFlow under the common alias `tf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b156f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import TensorFlow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) # find the version number where number should 2.x+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e1db4",
   "metadata": {},
   "source": [
    "## Creating Tensors with `tf.constant()`\n",
    "\n",
    "As mentioned before, in general, you usually won't create tensors yourself. This is because TensorFlow has built-in module such as (such as [`tf.io`](https://www.tensorflow.org/api_docs/python/tf/io) and [`tf.data`](https://www.tensorflow.org/guide/data)) which are able to read your data sources and automatically convert them to tensors and then later on, nueral network models will process these for us. \n",
    "\n",
    "But for now, because we're getting familar with tensors themselves and how to manipulate them, we'll see how we can create them ourselves. \n",
    "\n",
    "We'll begin by using [`tf.constant()`](https://www.tensorflow.org/api_docs/python/tf/constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de01874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Scalar (rank 0 tensor)\n",
    "\n",
    "scalar = tf.constant(8)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088aec2b",
   "metadata": {},
   "source": [
    "A Scalar is known as a rank 0 tensor. Because it has no dimensions(it's just a number). \n",
    "\n",
    "> ðŸ”‘ **Note:** For now, you don't need to know too much about the different ranks of tensors (but we will see more on this later). The important point is knowing tensors can have an unlimited range of dimensions (the exact amount will depend on what data you're representing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of a dimensions of a tensor where ndim stands for number of dimensions\n",
    "\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector more than 0 dimensions\n",
    "\n",
    "vector = tf.constant([8, 8])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee84994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of a dimensions of our vector tensor\n",
    "\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix more than 1 dimensions\n",
    "\n",
    "matrix = tf.constant([[7, 70],\n",
    "                    [10, 7]])\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of the dimensions of matrix\n",
    "\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d0afa",
   "metadata": {},
   "source": [
    "By Default, TensorFlow Creates tensors with either an `int32` or `float32` datatype.\n",
    "\n",
    "This is known as [32-bit precision](https://en.wikipedia.org/wiki/Precision_(computer_science) (the higher the number, the more precise the number, the more space it takes up on your computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cf129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the another matrix and define the datatype\n",
    "\n",
    "another_matrix = tf.constant([[7.,10.],\n",
    "                             [3., 2.],\n",
    "                             [8.,9.]], dtype=tf.float16) # specify the datatype with 'dtype'\n",
    "\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcebc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though another matrix contains more numbers, its dimensions stay the same\n",
    "\n",
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1410901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about a tensor? (more than 2 dimensions, although, all of the above items are also technically tensors)\n",
    "\n",
    "tensor = tf.constant([[[3, 2, 1],\n",
    "                      [6, 5, 4]],\n",
    "                     [[9, 8, 7],\n",
    "                      [12, 11, 10]],\n",
    "                     [[15, 14, 13],\n",
    "                      [18, 17, 16]]])\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fef09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246c47f",
   "metadata": {},
   "source": [
    "This is known as rank 3 tensor `(tensor with 3 dimensions)`, however a tensor can have an arbitary (unlimited) amount of dimensions\n",
    "\n",
    "For example you might have turn a series of images into tensors with shape (224, 224, 3, 32), where:\n",
    "\n",
    "* 224, 224 (the first 2 dimensions) are the height and width of the images in pixels.\n",
    "* 3 is the number of colour channels of image (red, green, and blue).\n",
    "* 32 is the batch size (the number of images a neural network sees at any one time).\n",
    "\n",
    "All of the variables we have created are actually tensors. But you may also hear them referred to as their different names (the onces we gave them):\n",
    "\n",
    "* Scalar: a single number\n",
    "* Vector: a number with direction (<i>For example: wind speed with direction</i>)\n",
    "* matrix: a 2-dimensional array of number\n",
    "* tensor: an n-dimensional array of numbers (<i> Where n can be any number, a 0-dimesions tensor is a scalar, a 1-dimension tensor is a vector</i>)\n",
    "\n",
    "By research, what we've found is that the term matrix and tensor are often interchangably.\n",
    "\n",
    "Going forward since we're using TensorFlow, everything we refer to and use will be tensors.\n",
    "\n",
    "For more on the mathematical difference between scalars, vectors and matrices see the [visual algebra post by Math is Fun](https://www.mathsisfun.com/algebra/scalar-vector-matrix.html).\n",
    "\n",
    "![difference between scalar, vector, matrix, tensor](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566f732",
   "metadata": {},
   "source": [
    "## Creating Tensors with `tf.Variable()`\n",
    "\n",
    "You can also (although you likely rarely will, because often, when working with data, tensors are created for you automatically) create tensors using [`tf.Variable()`](https://www.tensorflow.org/api_docs/python/tf/Variable).\n",
    "\n",
    "The difference between `tf.Variable()` and `tf.constant()` is tensors created with `tf.constant()` are immutable (can't be changed, can only be used to create a new tensor), where as, tensors created with `tf.Variable()` are mutable (can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the same tensor with tf.Variable() and tf.constant()\n",
    "\n",
    "changeable_tensor = tf.Variable([3, 7])\n",
    "unchangeable_tensor = tf.constant([3, 7])\n",
    "\n",
    "print(changeable_tensor, '\\n', unchangeable_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0cc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to change one of the elements of the changable tensor.\n",
    "\n",
    "changeable_tensor[0] = 3\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7444af",
   "metadata": {},
   "source": [
    "To change an element of a `tf.Variable()` tensor requires the `assign()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will error (requires the .assign() method)\n",
    "\n",
    "changeable_tensor[0].assign(7) # Won't error\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489173f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will error (can't change `tf.constant()`)\n",
    "\n",
    "unchangeable_tensor[0].assign(7)\n",
    "unchangleable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966788f",
   "metadata": {},
   "source": [
    "Which one should you use? `tf.constant()` or `tf.Variable()`?\n",
    "\n",
    "It will depend on what your problem requires. However, most of the time, TensorFlow will automatically choose for you (when loading data or modelling data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1764d2cc",
   "metadata": {},
   "source": [
    "## Creating random tensors\n",
    "\n",
    "Random tensors are tensors of some abitrary size which contain random numbers.\n",
    "\n",
    "Why would you want to create random tensors? \n",
    "\n",
    "This is what neural networks use to intialize their weights (patterns) that they're trying to learn in the data.\n",
    "\n",
    "For example, the process of a neural network learning often involves taking a random n-dimensional array of numbers and refining them until they represent some kind of pattern (a compressed way to represent the original data).\n",
    "\n",
    "**How a network learns**\n",
    "![how a network learns](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-how-a-network-learns.png)\n",
    "*A network learns by starting with random patterns (1) then going through demonstrative examples of data (2) whilst trying to update its random patterns to represent the examples (3).*\n",
    "\n",
    "We can create random tensors by using the [`tf.random.Generator`](https://www.tensorflow.org/guide/random_numbers#the_tfrandomgenerator_class) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d886fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two random (but the same) tensors\n",
    "random_1 = tf.random.Generator.from_seed(42) # set the seed for reproducibility\n",
    "random_1 = random_1.normal(shape=(3, 2)) # create tensor from a normal distribution \n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "\n",
    "# Are they equal?\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2095e",
   "metadata": {},
   "source": [
    "The random tensors we've created are actually [pseudorandom numbers](https://www.computerhope.com/jargon/p/pseudo-random.htm) (they appear as random, but really aren't).\n",
    "\n",
    "If we set a seed we'll get the same random numbers (if you've ever used NumPy, this is similar to `np.random.seed(42)`). \n",
    "\n",
    "Setting the seed says, \"hey, create some random numbers, but flavour them with X\" (X is the seed).\n",
    "\n",
    "What do you think will happen when we change the seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c99612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two random and different tensors\n",
    "\n",
    "random_3 = tf.random.Generator.from_seed(42)\n",
    "random_3 = random_3.normal(shape=(3, 2))\n",
    "random_4 = tf.random.Generator.from_seed(11)\n",
    "random_4 = random_4.normal(shape=(3, 2))\n",
    "\n",
    "# check the tensors and see if they are equal\n",
    "\n",
    "random_3, random_4, random_1 == random_3, random_3 == random_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233727a8",
   "metadata": {},
   "source": [
    "What if you wanted to shuffle the order of a tensor? \n",
    "\n",
    "Wait, Wait, Why you want you want to shuffle the order of tensor?\n",
    "\n",
    "Let's say you working with 20,000 images of cats and dogs and the first 15,000 images of were of cats and rest 5,000 were images of dogs. This order could effect how a neural network learns (it may overfit by learning the order of the data), instead, it might be a good idea to move your data around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle a tensor (valuable for when you want to shuffle your data)\n",
    "\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                            [3, 4],\n",
    "                            [2, 5]])\n",
    "\n",
    "# Gets different results each tim\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d60cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle in the same order every time using the seed parameter (won't actually be the same)\n",
    "\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e459f",
   "metadata": {},
   "source": [
    "Wait... why didn't the numbers come out the same?\n",
    "\n",
    "It's due to rule #4 of the [`tf.random.set_seed()`](https://www.tensorflow.org/api_docs/python/tf/random/set_seed) documentation.\n",
    "\n",
    "> \"4. If both the global and the operation seed are set: Both seeds are used in conjunction to determine the random sequence.\"\n",
    "\n",
    "`tf.random.set_seed(42)` sets the global seed, and the `seed` parameter in `tf.random.shuffle(seed=42)` sets the operation seed.\n",
    "\n",
    "Because, \"Operations that rely on a random seed actually derive it from two seeds: the global and operation-level seeds. This sets the global seed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81453bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle in the same order every time\n",
    "\n",
    "# Set the global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set the operation random seed\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the global random seed\n",
    "tf.random.set_seed(42) # if you comment this out you'll get different results\n",
    "\n",
    "# Set the operation random seed\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f9f4c",
   "metadata": {},
   "source": [
    "## Other ways to make tensors \n",
    "\n",
    "Though you might rarely use these (remember, many tensor operations are done behind the scenes for you), you can use `tf.ones()` to create a tensor of all ones and `tf.zeros()` to create a  tensor of all zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a tensor of all ones\n",
    "\n",
    "tf.ones(shape = (3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a tensor of all zeros\n",
    "\n",
    "tf.zeros(shape =(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfeb52",
   "metadata": {},
   "source": [
    "You can also turn NumPy arrays in into tensors\n",
    "\n",
    "Remember, the main difference between tensors and NumPy arrays is that tensors can be run on GPUs.\n",
    "\n",
    "> ðŸ”‘ **Note:** A matrix or tensor is typically represented by a capital letter (e.g. `X` or `A`) where as a vector is typically represented by a lowercase letter (e.g. `y` or `b`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd57817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_A = np.arange(0, 30, dtype = np.int32) # Create a NumPy array between 1 to 30\n",
    "\n",
    "A = tf.constant(numpy_A, shape = [2, 5, 3] ) # Note: the shape total (2 * 10 * 3) has to match the number of elements in the array\n",
    "\n",
    "print('NumPy \\n', numpy_A , '\\n\\n Tensor \\n', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d1c95",
   "metadata": {},
   "source": [
    "## Getting information from Tensor (shape, rank, size)\n",
    "\n",
    "There will be times when you will want to get different pieces of informaation from your tensors, in general, you  should know the following tensor vocabulary:\n",
    "\n",
    "* <b> Shape <b>: The length (number of elements) of each of the following dimensions of a tensor.\n",
    "* <b> Rank </b>: The number of tensor dimensions. A `Scalar` has rank 0, a `Vector` has rank 1, a `Matrix` has a rank 2, and a `Tensor` has rank n. \n",
    "* <b> Axis </b> or <b> Dimensions</b> : A particular dimension of a tensor. \n",
    "* <b> Size </b>: The total number of items in a tensor.\n",
    "\n",
    "You will use these especially when you are trying to line up the shapes of you data to the shapes of your model. For example, making sure the shape of your image tensors are the same shape  as your models input layer.\n",
    "    \n",
    "We have already seen one of these before using the `ndim` attribute.\n",
    "    \n",
    "#### Let's see the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ran 4 tensor (4 dimensions)\n",
    "\n",
    "rank_4_tensor  = tf.ones([2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get various attributes of tensor\n",
    "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (2*3*4*5):\", tf.size(rank_4_tensor).numpy()) # .numpy() converts to NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a132e1",
   "metadata": {},
   "source": [
    "> ðŸ”‘ **Note:** You can also index tensors just like Python Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 2 items of each dimensions\n",
    "\n",
    "rank_4_tensor[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0022fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimension from  each index except for the final one\n",
    "\n",
    "rank_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6092524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a rank 2 tensor (2 dimensions)\n",
    "\n",
    "rank_2_tensor = tf.zeros([2, 2])\n",
    "\n",
    "# Get the last item of each row\n",
    "\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0857b2f",
   "metadata": {},
   "source": [
    "> ðŸ”‘ **Note:** You can also add dimensions to your tensor at the same time keeping the same information present using `tf.newaxis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rank_2_tensor = tf.constant([[2, 3],\n",
    "                                [4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927389a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an extra dimension (to the end)\n",
    "rank_3_tensor = new_rank_2_tensor[..., tf.newaxis] # in Python \"...\" means \"all dimensions prior to\"\n",
    "new_rank_2_tensor, rank_3_tensor # shape (2, 2), shape (2, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281380c2",
   "metadata": {},
   "source": [
    "You can achieve the same using [`tf.expand_dims()`](https://www.tensorflow.org/api_docs/python/tf/expand_dims)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(new_rank_2_tensor, axis=-1) # \"-1\" means last axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3918bb3",
   "metadata": {},
   "source": [
    "## Manipuating tensors (tensor operations)\n",
    "\n",
    "Finding Patterns in tensors (numberical representation of data) requires manipulating them.\n",
    "\n",
    "Again, when building models in TensorFlow, much of this pattern discovery is done for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648f7db",
   "metadata": {},
   "source": [
    "## Basic Operations \n",
    "\n",
    "You can perform many of the basic mathematical operations directly on tensors using Python operations such as `+`, `-`, `*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add values to a tensor using the addition operator\n",
    "\n",
    "tensor = tf.constant([[7, 10], [4, 3]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c46c1",
   "metadata": {},
   "source": [
    "Since we used `tf.constant()`, the original tensor is unchanged (the addition gets on a copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ca8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tensor unchanged \n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa9d48",
   "metadata": {},
   "source": [
    "Other operators also work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplication (known as element-wise multiplication)\n",
    "\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtraction\n",
    "\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae36930",
   "metadata": {},
   "source": [
    "You can also use the equivalent TensorFlow operation. Using the TensorFlow function (where possible) has the advantage of being speed up later down the line when running as a part of a [TensorFlow graph](https://www.tensorflow.org/tensorboard/graphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TensorFlow function equivalent of the '*' (multiply) operator\n",
    "\n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original tensor is still unchanged\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61cf7e",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "One of the most common operations in the Machine Learning algorithms is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "TensorFlow implements this matrix multiplication functionality in the [`tf.matmul()`](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul) method.\n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "1. The inner dimensions must match:\n",
    "  * `(3, 5) @ (3, 5)` won't work\n",
    "  * `(5, 3) @ (3, 5)` will work\n",
    "  * `(3, 5) @ (5, 3)` will work\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    " * `(5, 3) @ (3, 5)` -> `(5, 5)`\n",
    " * `(3, 5) @ (5, 3)` -> `(3, 3)`\n",
    " \n",
    "> ðŸ”‘ **Note:** '`@`' in Python is the symbol for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication in TensorFlow\n",
    "\n",
    "print(tensor)\n",
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a30aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication with Python operator '@'\n",
    "\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904276d",
   "metadata": {},
   "source": [
    "Both of these examples work because our `tensor` variable is of shape (2, 2).\n",
    "\n",
    "What if we created some tensors which had mismatched shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create (3, 2) tensor\n",
    "A = tf.constant([[1, 2],\n",
    "                 [3, 4],\n",
    "                 [5, 6]])\n",
    "\n",
    "# Create another (3, 2) tensor\n",
    "B = tf.constant([[7, 8],\n",
    "                 [9, 10],\n",
    "                 [11, 12]])\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to matrix multiply them (will error)\n",
    "\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbabc7c1",
   "metadata": {},
   "source": [
    "Trying to matrix multiply two tensors with the shape `(3, 2)` errors because the inner dimensions don't match.\n",
    "\n",
    "We need to either:\n",
    "* Reshape A to `(2, 3)` so it's `(2, 3) @ (3, 2)`.\n",
    "* Reshape B to `(3, 2)` so it's `(3, 2) @ (2, 3)`.\n",
    "\n",
    "We can do this with either:\n",
    "* [`tf.reshape()`](https://www.tensorflow.org/api_docs/python/tf/reshape) - allows us to reshape a tensor into a defined shape.\n",
    "* [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) - switches the dimensions of a given tensor.\n",
    "\n",
    "![lining up dimensions for dot products](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-lining-up-dot-products.png)\n",
    "\n",
    "Let's try `tf.reshape()` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc457c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of reshape (3, 2) -> (2, 3)\n",
    "\n",
    "tf.reshape(B, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e89d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try matrix multiplication with reshaped Y\n",
    "\n",
    "A @ tf.reshape(B, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f12fd4",
   "metadata": {},
   "source": [
    "It worked, let's try the same with a reshaped `A`, except this time we'll use [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) and `tf.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of transpose (3, 2) -> (2, 3)\n",
    "\n",
    "tf.transpose(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try matrix multiplication \n",
    "tf.matmul(tf.transpose(A), B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297676c",
   "metadata": {},
   "source": [
    "Notice the difference in the resulting shapes when tranposing `A` or reshaping `B`.\n",
    "\n",
    "This is because of the 2nd rule mentioned above:\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)` done with `A @ tf.reshape(Y, shape=(2, 3))` \n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)` done with `tf.matmul(tf.transpose(A), B)`\n",
    "\n",
    "This kind of data manipulation is a reminder: you'll spend a lot of your time in machine learning and working with neural networks reshaping data (in the form of tensors) to prepare it to be used with various operations (such as feeding it to a model).\n",
    "\n",
    "### The dot product\n",
    "\n",
    "Multiplying matrices by eachother is also referred to as the dot product.\n",
    "\n",
    "You can perform the `tf.matmul()` operation using [`tf.tensordot()`](https://www.tensorflow.org/api_docs/python/tf/tensordot). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform matrix multiplication between A and B (transposed)\n",
    "\n",
    "tf.matmul(A, tf.transpose(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f637b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform matrix multiplication between A and B (reshaped)\n",
    "tf.matmul(A, tf.reshape(B, (2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26851f",
   "metadata": {},
   "source": [
    "Hmm... they result in different values.\n",
    "\n",
    "Which is strange because when dealing with `B` (a `(3x2)` matrix), reshaping to `(2, 3)` and tranposing it result in the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee76b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shapes of B, reshaped B and tranposed B\n",
    "\n",
    "B.shape, tf.reshape(B, (2, 3)).shape, tf.transpose(B).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fb03b",
   "metadata": {},
   "source": [
    "But calling `tf.reshape()` and `tf.transpose()` on `B` don't necessarily result in the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check values of B, reshape B and tranposed B\n",
    "\n",
    "print(\"Normal B:\")\n",
    "print(B, \"\\n\") # \"\\n\" for newline\n",
    "\n",
    "print(\"B reshaped to (2, 3):\")\n",
    "print(tf.reshape(B, (2, 3)), \"\\n\")\n",
    "\n",
    "print(\"B transposed:\")\n",
    "print(tf.transpose(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c60ff",
   "metadata": {},
   "source": [
    "As you can see, the outputs of `tf.reshape()` and `tf.transpose()` when called on `B`, even though they have the same shape, are different.\n",
    "\n",
    "This can be explained by the default behaviour of each method:\n",
    "* [`tf.reshape()`](https://www.tensorflow.org/api_docs/python/tf/reshape) - change the shape of the given tensor (first) and then insert values in order they appear (in our case, 7, 8, 9, 10, 11, 12).\n",
    "* [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) - swap the order of the axes, by default the last axis becomes the first, however the order can be changed using the [`perm` parameter](https://www.tensorflow.org/api_docs/python/tf/transpose)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2423ac0",
   "metadata": {},
   "source": [
    "So which should you use?\n",
    "\n",
    "Again, most of the time these operations (when they need to be run, such as during the training a neural network, will be implemented for you).\n",
    "\n",
    "But generally, whenever performing a matrix multiplication and the shapes of two matrices don't line up, you will transpose (not reshape) one of them in order to line them up.\n",
    "\n",
    "### Matrix multiplication tidbits\n",
    "* If we transposed `B`, it would be represented as $\\mathbf{B}^\\mathsf{T}$ (note the capital T for tranpose).\n",
    "* Get an illustrative view of matrix multiplication [by Math is Fun](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "* Try a hands-on demo of matrix multiplcation: http://matrixmultiplication.xyz/ (shown below).\n",
    "\n",
    "![visual demo of matrix multiplication](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-matrix-multiply-crop.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a81b7",
   "metadata": {},
   "source": [
    "## Changing the datatype of a tensor\n",
    "\n",
    "Sometimes you'll want to alter the default datatype of your tensor. \n",
    "\n",
    "This is common when you want to compute using less precision (e.g. 16-bit floating point numbers vs. 32-bit floating point numbers). \n",
    "\n",
    "Computing with less precision is useful on devices with less computing capacity such as mobile devices (because the less bits, the less space the computations require).\n",
    "\n",
    "You can change the datatype of a tensor using [`tf.cast()`](https://www.tensorflow.org/api_docs/python/tf/cast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tensor with default datatype (float32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "\n",
    "# Create a new tensor with default datatype (int32)\n",
    "C = tf.constant([1, 7])\n",
    "B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from float32 to float16 (reduced precision)\n",
    "B = tf.cast(B, dtype=tf.float16)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc44894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from int32 to float32\n",
    "C = tf.cast(C, dtype=tf.float32)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d3e58",
   "metadata": {},
   "source": [
    "### Getting the absolute value\n",
    "Sometimes you'll want the absolute values (all values are positive) of elements in your tensors.\n",
    "\n",
    "To do so, you can use [`tf.abs()`](https://www.tensorflow.org/api_docs/python/tf/math/abs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor with negative values\n",
    "D = tf.constant([-7, -10])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute values\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea219236",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum (aggregation)\n",
    "\n",
    "You can quickly aggregate (perform a calculation on a whole tensor) tensors to find things like the minimum value, maximum value, mean and sum of all the elements.\n",
    "\n",
    "To do so, aggregation methods typically have the syntax `reduce()_[action]`, such as:\n",
    "* [`tf.reduce_min()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_min) - find the minimum value in a tensor.\n",
    "* [`tf.reduce_max()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_max) - find the maximum value in a tensor (helpful for when you want to find the highest prediction probability).\n",
    "* [`tf.reduce_mean()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean) - find the mean of all elements in a tensor.\n",
    "* [`tf.reduce_sum()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum) - find the sum of all elements in a tensor.\n",
    "* **Note:** typically, each of these is under the `math` module, e.g. `tf.math.reduce_min()` but you can use the alias `tf.reduce_min()`.\n",
    "\n",
    "Let's see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with 50 random values between 0 and 100\n",
    "E = tf.constant(np.random.randint(low=0, high=100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum\n",
    "tf.reduce_max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f722a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean\n",
    "tf.reduce_mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the sum\n",
    "tf.reduce_sum(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3451e4a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "You can also find the standard deviation ([`tf.reduce_std()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_std)) and variance ([`tf.reduce_variance()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_variance)) of elements in a tensor using similar methods.\n",
    "\n",
    "### Finding the positional maximum and minimum\n",
    "\n",
    "How about finding the position a tensor where the maximum value occurs?\n",
    "\n",
    "This is helpful when you want to line up your labels (say `['Green', 'Blue', 'Red']`) with your prediction probabilities tensor (e.g. `[0.98, 0.01, 0.01]`).\n",
    "\n",
    "In this case, the predicted label (the one with the highest prediction probability) would be `'Green'`.\n",
    "\n",
    "You can do the same for the minimum (if required) with the following:\n",
    "* [`tf.argmax()`](https://www.tensorflow.org/api_docs/python/tf/math/argmax) - find the position of the maximum element in a given tensor.\n",
    "* [`tf.argmin()`](https://www.tensorflow.org/api_docs/python/tf/math/argmin) - find the position of the minimum element in a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e723f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with 50 values between 0 and 1\n",
    "F = tf.constant(np.random.random(50))\n",
    "F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
