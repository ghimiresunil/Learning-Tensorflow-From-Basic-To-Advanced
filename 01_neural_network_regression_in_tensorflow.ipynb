{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924239c9",
   "metadata": {},
   "source": [
    "# 01: Neural Network Regression with TensorFlow\n",
    "\n",
    "As we all know that, there are many pre-defined definitions for a [`regression_problem`](https://en.wikipedia.org/wiki/Regression_analysis) but in our case, to simplify it to be: predicting a number:\n",
    "\n",
    "For example, you might want to:\n",
    "* Estimate or predict the cost of medical insurance based on a person's demographics (age, gender, sex, race).\n",
    "* Estimate or predict the price of a property based on the information you have about it (such as number of rooms, number of bathrooms)\n",
    "* Estimate or predict the co-ordinate of a bounding box of an item in an image.\n",
    "\n",
    "In this notebook, we are going to set the foundations for how can you build a neural network to detect patterns in a sample of inputs (this is your data), and then making a estimation/prediction (in a form of a number) based on those inputs.\n",
    "\n",
    "## What we are going to cover?\n",
    "\n",
    "Specially, we will go through how to use `TensorFlow` to perform the following:\n",
    "\n",
    "* Architecture of the regression model\n",
    "* Input shapes and output shapes\n",
    "    * `X`: Feature / Data (inputs)\n",
    "    * 'y': Label / Target (outputs)\n",
    "* Creating custom data to view and fit\n",
    "* Steps in modelling \n",
    "    * Creating a model\n",
    "    * Compiling a model\n",
    "        * Defining a loss function\n",
    "        * Setting up an optimizer \n",
    "        * Creating an evaluation metrics\n",
    "    * Fitting a model (getting it to find patterns in your data)\n",
    "* Evaluating a model\n",
    "    * Visualizing the model (`\"(3V) visualize, visualize, and visualize\"`)\n",
    "    * Looking at training curves\n",
    "    * Compare estimations/predictions to ground truth (using our evaluation metrices)\n",
    "* Saving a model (So we can use it for later)\n",
    "* Loading a saved model\n",
    "\n",
    "> ðŸ”‘ **Note:** Don't worry if none of these make sense right now, we'll go through each of them one by one.\n",
    "\n",
    "## How you can use this notebook?\n",
    "\n",
    "You can go through the explanations and code (everything should work), but there's a better way to run code.\n",
    "\n",
    "Write all of the code yourself.\n",
    "\n",
    "Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, why does it break?\n",
    "\n",
    "You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.\n",
    "\n",
    "Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to **write more code**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0f3e4",
   "metadata": {},
   "source": [
    "## Typical architecture of a regression neural network\n",
    "\n",
    "The word `typical` is on purpose. \n",
    "\n",
    "Why?\n",
    "\n",
    "Because there are so many distict methods to build a neural networks (almost an unlimited number of ways).\n",
    "\n",
    "However, the following is a typical framework for taking a set of numbers, detecting patterns in them, and then getting a target number.\n",
    "\n",
    "Yes, we know the previous sentence is vague but we'll see this in action shortly.\n",
    "\n",
    "| **Hyperparameter** | **Typical value** |\n",
    "| --- | --- |\n",
    "| Input layer shape | Same shape as number of features (e.g. 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction) |\n",
    "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
    "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
    "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
    "| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |\n",
    "| Output activation | None, ReLU, logistic/tanh |\n",
    "| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |\n",
    "| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |\n",
    "\n",
    "***Table 1:*** *Typical architecture of a regression network.* ***Source:*** *Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by AurÃ©lien GÃ©ron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n",
    "\n",
    "Again, if you're new to neural networks and deep learning in general, much of the above table won't make sense. But don't worry, we'll be getting hands-on with all of it soon.\n",
    "\n",
    "> ðŸ”‘ **Note:** A **hyperparameter** in machine learning is something a data analyst or developer can set themselves, where as a **parameter** usually describes something a model learns on its own (a value not explicitly set by an analyst).\n",
    "\n",
    "Okay, enough talk, let's get started writing code.\n",
    "\n",
    "To use TensorFlow, we will import as the common alias `tf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd05b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 09:22:03.572978: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-12 09:22:03.573006: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048e5cf",
   "metadata": {},
   "source": [
    "## Creating data to view and fit \n",
    "\n",
    "As we have discussed already about this notebook, so let's create some linear data (a straight line) to model for predicting a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80a9e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd12bac0ee0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features / input data\n",
    "X = np.array([14.0, 11.0, 8.0, 5.0, 2.0, -1.0, -4.0, -7.0])\n",
    "\n",
    "# Create label/target\n",
    "y = np.array([24.0, 21.0, 18.0, 15.0, 12.0, 9.0, 6.0, 3.0])\n",
    "\n",
    "# visualize \n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f221b6d5",
   "metadata": {},
   "source": [
    "A question may arise in your mind, can you compute the pattern between `X` and `y` before we start modeling?\n",
    "\n",
    "For example, if someone asked you, what would be the value of `y` if the value of `X` was found 19.0 or -15.0?\n",
    "\n",
    "This is the essence of what we'll be building neural network to perform for us.\n",
    "\n",
    "\n",
    "## Regression Input and Output Shapes\n",
    "\n",
    "One of the most important concepts when building a neural network are the input and output shapes.\n",
    "\n",
    "* The <b> input shape </b> is the shape of your data that goes into the model\n",
    "* The <b> output shape </b> is the shape of your data you want to come out of your model.\n",
    "\n",
    "The input and output shape will be differ based on the problem statement or depend on the problem you are working on.\n",
    "\n",
    "Neural networks accept numbers and output numbers. These numbers are typically represented as tensors (or arrays).\n",
    "\n",
    "Similar to NumPy Array, we could do same with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ec861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 09:22:12.877350: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-12 09:22:12.877428: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (linus-Inspiron-3543): /proc/driver/nvidia/version does not exist\n",
      "2022-01-12 09:22:12.886069: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# input and output shapes of a regression model\n",
    "\n",
    "building_info = tf.constant(['garage', 'bedrooms', 'bathrooms'])\n",
    "building_price = tf.constant([939700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf42043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of building:  tf.Tensor([b'garage' b'bedrooms' b'bathrooms'], shape=(3,), dtype=string)\n",
      "Price of building:  tf.Tensor([939700], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('Information of building: ', building_info)\n",
    "print('Price of building: ', building_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab53d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data: (3,)\n",
      "Shape of output data: (1,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of input data:', building_info.shape)\n",
    "print('Shape of output data:', building_price.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1bbac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd12408ec70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use tensors for first example\n",
    "\n",
    "# Create features / input data\n",
    "X = tf.constant([14.0, 11.0, 8.0, 5.0, 2.0, -1.0, -4.0, -7.0])\n",
    "\n",
    "# Create label/target\n",
    "y = tf.constant([24.0, 21.0, 18.0, 15.0, 12.0, 9.0, 6.0, 3.0])\n",
    "\n",
    "# visualize \n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0dbbf",
   "metadata": {},
   "source": [
    "Our goal here will be here to predict `y` using `X`.\n",
    "\n",
    "So, our input will be `X` and output will `y`.\n",
    "\n",
    "Now, question may arise in your mind, what do you think input and output shape will be?\n",
    "\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfa352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a single example of X\n",
    "input_shape = X[0].shape\n",
    "\n",
    "# Take a single example of y\n",
    "output_shape = y[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678dbe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b11ea1",
   "metadata": {},
   "source": [
    "Huh?\n",
    "\n",
    "From the above results, our inputs and outputs have no shape?\n",
    "\n",
    "How could that be?\n",
    "\n",
    "It is because no matter what kind of data we pass to our model, it is always going to take as input and return as output some kind of tensor.\n",
    "\n",
    "Still Confused?? ðŸ¤” ðŸ¤” \n",
    "\n",
    "In our case, we are working with two small lists of numbers or in other words we can say that we are looking at a special kind of tensor, more specificially rank 0 tensor or a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2e0eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=14.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=24.0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the single example individually\n",
    "\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ba4c1",
   "metadata": {},
   "source": [
    "In our case, we are trying to build a model to predict the pattern between `X` and `y`\n",
    "\n",
    "Where `X[0] is equal to 14.0 and y[0] equal to 24.0`\n",
    "\n",
    "Now, you might be clear about what are trying to do, we are using 1 `X` value to predict 1 `y` value.\n",
    "\n",
    "You might be thinking, \"this sounds quite difficult for only predicting a straight line....\"\n",
    "\n",
    "And the answer is Big YES....\n",
    "\n",
    "But the concepts we're covering here, the concepts of input and output shapes to a model are fundamental. \n",
    "\n",
    "In fact, they're probably two of the things you'll spend the most time on when you work with neural networks: **making sure your input and outputs are in the correct shape**.\n",
    "\n",
    "If it doesn't make sense now, we'll see plenty more examples later on (soon you'll notice the input and output shapes can be almost anything you can imagine).\n",
    "\n",
    "![example of input and output shapes for a housing price prediction problem](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/01-input-and-output-shapes-housing-prices.png)\n",
    "*If you were working on building a machine learning algorithm for predicting housing prices, your inputs may be number of bedrooms, number of bathrooms and number of garages, giving you an input shape of 3 (3 different features). And since you're trying to predict the price of the house, your output shape would be 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfb9d",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "\n",
    "In the above session, we have learned about data and it's input shapes and output shapes. Now, let's see how to build a Neural Network model using input and output data. \n",
    "\n",
    "To create and train a model, there are typically 3 fundamental steps in TensorFlow:\n",
    "\n",
    "* **Step 01 -> Creating a model:** Using a [`Functional`](https://www.tensorflow.org/guide/keras/functional) or [`Sequential API`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) piece together the layers of a neural network  yourself or import a previously built model (known as a `Transfer Learning`)\n",
    "<br> <br>\n",
    "* **Step 02 -> Compiling a model:** Determing and monitoring the performance of the model (`loss/metrics`) as well as how it should improve (`optimizer`)\n",
    "<br> <br>\n",
    "* **step 03 -> Fitting a model:** letting the model try to find patterns in the data (how does `X` get to `y`).\n",
    "<br> <br>\n",
    "\n",
    "Let's put all of the above steps into practice by creating a model for our regression data using the [`Keras Sequential API`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). Then we'll go through each one step by step. \n",
    "\n",
    "> **Note:** If you're using [TensorFlow 2.7.0](https://github.com/tensorflow/tensorflow/releases/tag/v2.7.0)+, the `fit()` function no longer upscales input data to go from `(batch_size, )` to `(batch_size, 1)`. To fix this, you'll need to expand the dimension of input data using `tf.expand_dims(input_data, axis=-1)`.\n",
    ">\n",
    "> In our case, this means instead of using `model.fit(X, y, epochs=5)`, use `model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3efa2956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd104f3ce80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the random state \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model using Squetial API\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae, # mae is short for mean absolute error\n",
    "             optimizer = tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
    "             metrics = ['mae'])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(tf.expand_dims(X, axis = -1), y, epochs = 5)\n",
    "# model.fit(X, y, epochs=5) # this will break with TensorFlow 2.7.0+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c0657",
   "metadata": {},
   "source": [
    "### <i> BOOM </i>\n",
    "\n",
    "\n",
    "We have just trained a model to figure out the patterns between `X` and `y`.\n",
    "\n",
    "How do you think it went?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25ecdd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([14., 11.,  8.,  5.,  2., -1., -4., -7.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([24., 21., 18., 15., 12.,  9.,  6.,  3.], dtype=float32)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c9f58",
   "metadata": {},
   "source": [
    "If someone asked you, what would be the value of y if the value of X was found 19.0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64058a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.2061405]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the prediction with the model\n",
    "\n",
    "model.predict([19.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62cb2e",
   "metadata": {},
   "source": [
    "It doesn't go very well.. the value of y should be something close to 29.0. \n",
    "\n",
    "> ðŸ¤” **Question:** What's Keras? I thought we were working with TensorFlow but every time we write TensorFlow code, `keras` comes after `tf` (e.g. `tf.keras.layers.Dense()`)?\n",
    "\n",
    "## Improving a model for better performance\n",
    "\n",
    "How do you think you'd improve upon our current model?\n",
    "\n",
    "You'd be right if you guessed by altering some of the things we performed above.\n",
    "\n",
    "To improve our model, we alter almost every part of the 3 steps we went through before.\n",
    "\n",
    "* **Creating a model:** \n",
    "    * Add more Layers\n",
    "    * Increase the number of hidden units (also called neurons) within each layer\n",
    "    * Change the activation function of each layer\n",
    "<br> <br>\n",
    "* **Compiling a model**: \n",
    "    * Choose the optimization function\n",
    "    * Change the **learning rate** of the optimization function\n",
    "<br> <br>\n",
    "\n",
    "* **Fitting a model**: \n",
    "    * Fit a model for more **epochs** (leave it traning for longer)\n",
    "    * More data (Give the model more examples to learn from)\n",
    "    \n",
    "*There are many different ways to potentially improve a neural network. Some of the most common include: increasing the number of layers (making the network deeper), increasing the number of hidden units (making the network wider) and changing the learning rate. Because these values are all human-changeable, they're referred to as [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) and the practice of trying to find the best hyperparameters is referred to as [hyperparameter tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization).*\n",
    "\n",
    "Woah. We just introduced a bunch of possible steps. The important thing to remember is how you alter each of these will depend on the problem you're working on.\n",
    "\n",
    "And the good thing is, over the next few problems, we'll get hands-on with all of them.\n",
    "\n",
    "For now, let's keep it simple, all we'll do is train our model for longer (everything else will stay the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30e97f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.9748 - mae: 10.9748\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.8423 - mae: 10.8423\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.7098 - mae: 10.7098\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.4448 - mae: 10.4448\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 10.3123 - mae: 10.3123\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.0473 - mae: 10.0473\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9148 - mae: 9.9148\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7823 - mae: 9.7823\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.6498 - mae: 9.6498\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5173 - mae: 9.5173\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3848 - mae: 9.384 - 0s 4ms/step - loss: 9.3848 - mae: 9.3848\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2523 - mae: 9.2523\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1198 - mae: 9.1198\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9873 - mae: 8.9873\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8548 - mae: 8.8548\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7223 - mae: 8.7223\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5898 - mae: 8.5898\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4573 - mae: 8.4573\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3248 - mae: 8.3248\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1923 - mae: 8.1923\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.0598 - mae: 8.0598\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.9273 - mae: 7.9273\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7948 - mae: 7.7948\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6623 - mae: 7.6623\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5298 - mae: 7.5298\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3973 - mae: 7.3973\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2648 - mae: 7.2648\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.1738 - mae: 7.173 - 0s 8ms/step - loss: 7.1738 - mae: 7.1738\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1063 - mae: 7.1063\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8869 - mae: 6.8869\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8813 - mae: 6.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd105e77e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model (same as above)\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
    "\n",
    "# Compile model (same as above)\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae, # mae is short for mean absolute error\n",
    "             optimizer = tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
    "             metrics = ['mae'])\n",
    "\n",
    "# Fit the model and this time we will train for longer\n",
    "\n",
    "model.fit(tf.expand_dims(X, axis = -1), y, epochs = 100) # train for 100 epochs not for 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e1aa3",
   "metadata": {},
   "source": [
    "While training for 100 epochs, you might noticed that the loss value decrease from top to bottom, also if we increase the size of the epochs, the loss function also decrease. \n",
    "\n",
    "<i> **Note: Increase in epochs, decrease the loss function** </i>\\\n",
    "\n",
    "What do you think this means for when we make a prediction with our model?\n",
    "\n",
    "How about we try predict on 19.0 again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7abaf53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([14., 11.,  8.,  5.,  2., -1., -4., -7.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([24., 21., 18., 15., 12.,  9.,  6.,  3.], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of what X and y are\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd77ca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33.60863]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and predict what y would be if X was 17.0\n",
    "\n",
    "model.predict([19.0]) # the right answer is 27.0 (y = X + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba4932",
   "metadata": {},
   "source": [
    "Much better!! ðŸ˜Š\n",
    "\n",
    "We got closer this time. But we could still be better.\n",
    "\n",
    "Now we've trained a model, how could we evaluate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468d381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
